{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from smooth import smoothen\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filelist = [\"calcium_data/140708B_140811a_result\", \n",
    "            \"calcium_data/140909C_141112a_result\", \n",
    "            \"calcium_data/141006C_141121a_result\",\n",
    "            \"calcium_data/150109A_150302a_result\", \n",
    "            \"calcium_data/151122A_160202a_result\", \n",
    "            \"calcium_data/151122B_160207a_result\", \n",
    "            \"calcium_data/160209A_160430a_result\", \n",
    "            \"calcium_data/160209B_160428a_result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "experiemntal parameters:\n",
    "\n",
    "v(0): hit/miss, +1 for hit, -1 for miss\n",
    "\n",
    "v(1): stimulus intensity\n",
    "\n",
    "v(2): rest of variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocessing(filename, time='full', windows=None, z_score=True, smooth=True):\n",
    "    '''\n",
    "    Preprocesses the data according to specified parameters\n",
    "    \n",
    "    filename: string, specifies file to use. If None, concatenate all files\n",
    "    time: string\n",
    "        'full' - use full time series of the dendritic Ca2+ signal\n",
    "        'windowed' - use only one point per dendrite, averaged over specified window\n",
    "    windows: ndarray, 7x2 or n_filesx7x2. \n",
    "        Required in windowed mode. Array holds start- and stop times for each stimulus.\n",
    "    z_score: bool, whether to z-score the data. \n",
    "    '''\n",
    "    \n",
    "    assert(not(time=='windowed') or not(windows == None))\n",
    "    \n",
    "    #get the data we need into the format we need\n",
    "    if type(filename) == list:\n",
    "        #create concatenated data, prompt if file already exitsts\n",
    "        #in this case, other experiments are interpreted as different units, but same trials as\n",
    "        #other units. Not all experiments have same units, and not same stimuli, so...later.\n",
    "        try:\n",
    "            f = h5py.File('allexp.hdf5', 'w-')\n",
    "        except OSError:\n",
    "            print('file already exists, type \"continue\" to overwrite \\n')\n",
    "            if input() == 'continue':\n",
    "                f = h5py.File('allexp.hdf5', 'w')\n",
    "                \n",
    "        #filename denotes a list of files in this case\n",
    "        for file in filename:\n",
    "            #finish later, or probably not\n",
    "            pass\n",
    "    else:\n",
    "        #just load data from specified file\n",
    "        f = h5py.File(filename+'.hdf5', 'r')\n",
    "        g = h5py.File(filename[:-6]+\"roi.hdf5\", \"r\")\n",
    "        motion_mask = (g['inFrameDend'][:].astype(bool)).reshape(g['inFrameDend'].shape[0])\n",
    "        \n",
    "        data = f['data'][:, motion_mask, :]\n",
    "        meta = f['meta']\n",
    "    \n",
    "    if time == 'full':\n",
    "        #keep all times\n",
    "        data_pass = data[:]\n",
    "        if smooth:\n",
    "            #if we smoothen the data\n",
    "            data_pass = smoothen(filename)[:,motion_mask,:]\n",
    "        meta_pass = meta[:]\n",
    "        \n",
    "    if time == 'windowed':\n",
    "        #get window-averaged\n",
    "        meta_pass = meta[:]\n",
    "        data_pass = np.zeros((data.shape[0], data.shape[1]))\n",
    "        \n",
    "        stims = np.unique(meta[:,1])\n",
    "        for i, amp in enumerate(stims):\n",
    "            amp_mask = meta[:,1] == amp\n",
    "            data_pass[amp_mask] = np.mean(data[amp_mask,:,windows[i,0], windows[i,1]], axis=2)\n",
    "            \n",
    "    if z_score:\n",
    "        #z_score signal\n",
    "        mns = np.mean(data_pass, axis=0)\n",
    "        try:\n",
    "        #specify exception\n",
    "            mns = np.mean(mns, axis=1)\n",
    "        except:\n",
    "            print('Exception triggered')\n",
    "            \n",
    "        try:\n",
    "            stds = np.std(data_pass, axis=(0,2))\n",
    "        except:\n",
    "            print('Exception triggered')\n",
    "            \n",
    "        mns = np.transpose(np.tile(mns, (data.shape[0], data.shape[2], 1)), axes=[0,2,1])\n",
    "        stds = np.transpose(np.tile(stds, (data.shape[0], data.shape[2], 1)), axes=[0,2,1])\n",
    "        \n",
    "        data_pass = data_pass - mns\n",
    "        data_pass = data_pass/stds\n",
    "            \n",
    "    #possibly add functionality for subtracting mean, but not dividing by std.\n",
    "    return meta_pass, data_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_betas(meta, data):\n",
    "    n_trials = data.shape[0]\n",
    "    n_units = data.shape[1]\n",
    "    n_times = data.shape[2]\n",
    "    \n",
    "    F_i = np.ones((3, n_trials))\n",
    "    F_i[0, :] = meta[:, 2]\n",
    "    F_i[1, :] = meta[:, 1]\n",
    "    \n",
    "    #tensor math more efficient?\n",
    "    beta = np.zeros((n_units, n_times, 3))\n",
    "    F_fac = np.dot(np.linalg.inv(np.dot(F_i, F_i.T)), F_i)\n",
    "    \n",
    "    for i in range(n_units):\n",
    "        for t in range(n_times):\n",
    "            r_it = data[:,i,t]\n",
    "            beta[i, t, :] = F_fac.dot(r_it)\n",
    "            \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_population_response(meta, data):\n",
    "    '''\n",
    "    returns ndarray of shape conditions x times x units\n",
    "    '''\n",
    "    n_units = data.shape[1]\n",
    "    n_trials = data.shape[0]\n",
    "    n_times = data.shape[2]\n",
    "    \n",
    "    stims = np.unique(meta[:,1])\n",
    "    n_stims = stims.shape[0]\n",
    "    \n",
    "    #get mask for hit- and miss conditions\n",
    "    hit_mask = meta[:, 2] == 1\n",
    "    miss_mask = meta[:, 2] == 0\n",
    "    \n",
    "    hit_stim_masks = []\n",
    "    miss_stim_masks = []\n",
    "    \n",
    "    #get masks for all stimulus conditions\n",
    "    for stim in stims:\n",
    "        stim_mask = meta[:, 1] == stim\n",
    "        hit_stim_masks.append(np.logical_and(stim_mask, hit_mask))\n",
    "        miss_stim_masks.append(np.logical_and(stim_mask, miss_mask))\n",
    "        \n",
    "    n_conditions = len(hit_stim_masks) + len(miss_stim_masks)\n",
    "\n",
    "    x = np.zeros((n_conditions, n_times, n_units))\n",
    "    #CONVENTION: all hit, then all miss\n",
    "    \n",
    "    for i in range(n_conditions):\n",
    "        if i < len(hit_stim_masks):\n",
    "            x[i, :, :] = np.mean(data[hit_stim_masks[i]], axis=0).T\n",
    "        else:\n",
    "            i = i%len(hit_stim_masks)\n",
    "            x[i, :, :] = np.mean(data[miss_stim_masks[i]], axis=0).T\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_X_PCA():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meta, data = preprocessing(filelist[0], time='full', windows=None, z_score=True, smooth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta = get_betas(meta, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = get_population_response(meta, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.14849715,  0.28754762, -0.04867248, -0.07447999, -0.06215255,\n",
       "       -0.1042335 ,  0.02175858, -0.07586941, -0.18940984,  0.05272575,\n",
       "       -0.05978899, -0.17362823, -0.24208255,  0.30556657, -0.13914806,\n",
       "       -0.02655665,  0.06397083, -0.15002965, -0.01481979,  0.06730582,\n",
       "        0.19044269,  0.05450866, -0.24650156, -0.3023079 , -0.19561972,\n",
       "        0.00427318,  0.08992673, -0.02306731,  0.19891316, -0.12063751,\n",
       "        0.0618432 ,  0.02906641,  0.26620874,  0.04166446, -0.00549963,\n",
       "        0.14641239, -0.22778411, -0.15444401, -0.25007022, -0.18399296,\n",
       "        0.02910131,  0.0179669 ,  0.10009634, -0.05261634, -0.21726763,\n",
       "        0.12593191, -0.01440529, -0.32740382,  0.02243236, -0.05981341,\n",
       "       -0.15144596,  0.10418613, -0.28803781, -0.30202223, -0.01352433,\n",
       "       -0.11030802, -0.048679  , -0.20885005,  0.03110869, -0.05085603,\n",
       "       -0.14285281,  0.08259193, -0.01193314, -0.16655303,  0.24061088,\n",
       "       -0.03896131,  0.23778656,  0.1444806 , -0.2932495 , -0.1093909 ,\n",
       "       -0.3186567 , -0.03950508, -0.13608622,  0.14653197, -0.05000489,\n",
       "        0.05571278,  0.01704781, -0.03615187, -0.04454501, -0.0272843 ,\n",
       "       -0.31691636, -0.07139699, -0.02380367, -0.01424375, -0.10503545,\n",
       "       -0.13832115, -0.03484101, -0.05400271, -0.22417952,  0.00076565,\n",
       "       -0.06942461, -0.04067109, -0.35276145, -0.33308057, -0.0663279 ,\n",
       "       -0.23292148, -0.00245901, -0.13501402, -0.1830465 , -0.19592822,\n",
       "        0.15500147, -0.0943376 , -0.05389109, -0.15543557, -0.29009493,\n",
       "       -0.14866954, -0.32053961, -0.04732204,  0.00317901])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
